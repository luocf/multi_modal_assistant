from typing import Dict, Any, Optional, List
import time
import logging
import asyncio
from dataclasses import dataclass
from enum import Enum
import numpy as np
import cv2

from datetime import datetime
from loguru import logger

from app.core.perception.face_recognizer import FaceRecognizer
from app.core.perception.voice_recognizer import VoiceRecognizer
from app.core.dialogue.dialogue_manager import DialogueManager
from app.core.user.user_manager import UserManager
from app.models.model_factory import ModelFactory
from app.config.user_config import USER_CONFIG
from app.config.voice_config import VOICE_CONFIG
from app.config.model_config import ModelType
from app.config.audio_config import AUDIO_CONFIG
from app.core.perception.emotion_recognizer import EmotionRecognizer
from app.core.perception.gesture_recognizer import GestureRecognizer
from app.core.utils import encrypt_data, decrypt_data

# ç³»ç»ŸçŠ¶æ€æšä¸¾
class SystemState(Enum):
    """ç³»ç»ŸçŠ¶æ€æšä¸¾"""
    IDLE = "idle"           # ç©ºé—²çŠ¶æ€
    LISTENING = "listening" # æ­£åœ¨å¬
    THINKING = "thinking"   # æ­£åœ¨æ€è€ƒ
    SPEAKING = "speaking"   # æ­£åœ¨è¯´è¯
    ERROR = "error"         # é”™è¯¯çŠ¶æ€

# ç”¨æˆ·çŠ¶æ€æšä¸¾
class UserState(Enum):
    UNKNOWN = "unknown"
    IDENTIFIED = "identified"
    ACTIVE = "active"
    INACTIVE = "inactive"

# ç³»ç»Ÿé…ç½®ç±»
class SystemConfig:
    """ç³»ç»Ÿé…ç½®"""
    def __init__(self):
        self.model_config = ModelType.LIGHT.value  # ä½¿ç”¨æšä¸¾å€¼
        self.audio_config = {
            "format": "int16",
            "channels": 1,
            "rate": 16000,
            "chunk": 1024
        }
        self.logger = logger
        
        self.recognition_config = {
            "face_confidence_threshold": 0.6,
        }
        
        self.performance_config = {
            "skip_frames": 2,
            "batch_size": 1
        }

# ç³»ç»Ÿç®¡ç†å™¨
class SystemManager:
    def __init__(self):
        self.state = SystemState.INITIALIZING
        self.config = SystemConfig()
        self.logger = logging.getLogger(__name__)
        
    def initialize(self):
        """åˆå§‹åŒ–ç³»ç»Ÿ"""
        try:
            self._load_models()
            self._initialize_modules()
            self.state = SystemState.READY
        except Exception as e:
            self.logger.error(f"ç³»ç»Ÿåˆå§‹åŒ–å¤±è´¥: {str(e)}")
            self.state = SystemState.ERROR
            raise
            
    def _load_models(self):
        """åŠ è½½æ¨¡å‹"""
        pass
        
    def _initialize_modules(self):
        """åˆå§‹åŒ–å„ä¸ªæ¨¡å—"""
        pass


# å¯¹è¯å¼•æ“
class DialogueEngine:
    def __init__(self):
        """åˆå§‹åŒ–å¯¹è¯å¼•æ“"""
        self.model = ModelFactory.create_model("light")  # ä½¿ç”¨lightæ¨¡å‹
        self.last_response = "ä½ å¥½ï¼æˆ‘æ˜¯ä½ çš„AIåŠ©æ‰‹ã€‚"
        self.is_processing = False
        self.response_cache = {}  # ç¼“å­˜ç”¨æˆ·è¾“å…¥å¯¹åº”çš„å“åº”
        self.cache_size = 100  # ç¼“å­˜å¤§å°
        self.max_cache_age = 3600  # ç¼“å­˜æœ‰æ•ˆæœŸï¼ˆç§’ï¼‰
        self.last_context = None  # è®°å½•ä¸Šä¸€æ¬¡çš„ä¸Šä¸‹æ–‡
        self.context_similarity_threshold = 0.8  # ä¸Šä¸‹æ–‡ç›¸ä¼¼åº¦é˜ˆå€¼
        
    def process_input(self, text: str, context: Optional[Dict[str, Any]] = None) -> str:
        """å¤„ç†ç”¨æˆ·è¾“å…¥"""
        if self.is_processing:
            return self.last_response
            
        # æ£€æŸ¥ä¸Šä¸‹æ–‡ç›¸ä¼¼åº¦
        if context and self.last_context:
            similarity = self._calculate_context_similarity(context, self.last_context)
            if similarity > self.context_similarity_threshold:
                return self.last_response
                
        # æ£€æŸ¥ç¼“å­˜
        cache_key = f"{text}_{str(context)}"
        if cache_key in self.response_cache:
            cached_response, timestamp = self.response_cache[cache_key]
            if time.time() - timestamp < self.max_cache_age:
                return cached_response
                
        try:
            self.is_processing = True
            # æ„å»ºæç¤ºè¯
            prompt = self._build_prompt(text, context)
            
            # ç”Ÿæˆå›å¤
            response = self.model.generate(prompt)
            self.last_response = response
            self.last_context = context
            
            # æ›´æ–°ç¼“å­˜
            self._update_cache(cache_key, response)
            
            return response
            
        except Exception as e:
            logger.error(f"å¤„ç†ç”¨æˆ·è¾“å…¥å¤±è´¥: {e}")
            return "æŠ±æ­‰ï¼Œæˆ‘ç°åœ¨æ— æ³•å›åº”ï¼Œè¯·ç¨åå†è¯•ã€‚"
        finally:
            self.is_processing = False
            
    def _calculate_context_similarity(self, context1: Dict[str, Any], context2: Dict[str, Any]) -> float:
        """è®¡ç®—ä¸¤ä¸ªä¸Šä¸‹æ–‡çš„ç›¸ä¼¼åº¦"""
        if not context1 or not context2:
            return 0.0
            
        # æ¯”è¾ƒäººè„¸æ£€æµ‹ç»“æœ
        face1 = context1.get("face", {})
        face2 = context2.get("face", {})
        
        if face1.get("detected") != face2.get("detected"):
            return 0.0
            
        if face1.get("detected"):
            # å¦‚æœéƒ½æ£€æµ‹åˆ°äººè„¸ï¼Œæ¯”è¾ƒç½®ä¿¡åº¦
            conf1 = face1.get("confidence", 0.0)
            conf2 = face2.get("confidence", 0.0)
            return 1.0 - abs(conf1 - conf2)
            
        return 1.0  # å¦‚æœéƒ½æ²¡æœ‰æ£€æµ‹åˆ°äººè„¸ï¼Œè®¤ä¸ºä¸Šä¸‹æ–‡ç›¸ä¼¼
        
    def _update_cache(self, key: str, response: str):
        """æ›´æ–°å“åº”ç¼“å­˜"""
        # å¦‚æœç¼“å­˜å·²æ»¡ï¼Œåˆ é™¤æœ€æ—§çš„æ¡ç›®
        if len(self.response_cache) >= self.cache_size:
            oldest_key = min(self.response_cache.keys(), 
                           key=lambda k: self.response_cache[k][1])
            del self.response_cache[oldest_key]
            
        self.response_cache[key] = (response, time.time())
        
    def _build_prompt(self, text: str, context: Optional[Dict[str, Any]] = None) -> str:
        """æ„å»ºprompt"""
        prompt = f"User: {text}\n"
        if context and context.get("face", {}).get("detected"):
            prompt += "ç³»ç»Ÿæ£€æµ‹åˆ°äººè„¸ï¼Œè¯·ä¿æŒå‹å¥½å’Œä¸“ä¸šçš„å¯¹è¯é£æ ¼ã€‚\n"
        prompt += "Assistant: "
        return prompt

# ä¸»åº”ç”¨ç±»
class MultiModalAssistant:
    """å¤šæ¨¡æ€åŠ©æ‰‹"""
    def __init__(self):
        """åˆå§‹åŒ–å¤šæ¨¡æ€åŠ©æ‰‹"""
        self.system_state = SystemState.IDLE
        self.last_response_time = datetime.now()
        self.is_running = False
        
        # åˆå§‹åŒ–å„ä¸ªç»„ä»¶
        self.dialogue_manager = DialogueManager()
        self.voice_recognizer = VoiceRecognizer(VOICE_CONFIG)
        
        # ä¸º FaceRecognizer åˆ›å»ºé…ç½®
        face_config = {
            "face_confidence_threshold": 0.6,
            "model_path": None,  # ä½¿ç”¨é»˜è®¤æ¨¡å‹
            "device": "cpu"
        }
        self.face_recognizer = FaceRecognizer(face_config)
        self.user_manager = UserManager(USER_CONFIG)
        self.emotion_recognizer = EmotionRecognizer({"model_type": "fer"})
        self.gesture_recognizer = GestureRecognizer({})
        self.identity_manager = None  # å¯é€‰ï¼šå¦‚æœ‰ identity_manager æ¨¡å—
        
        logger.info("å¤šæ¨¡æ€åŠ©æ‰‹åˆå§‹åŒ–å®Œæˆ")
        
    def start(self):
        """å¯åŠ¨ç³»ç»Ÿ"""
        if self.is_running:
            logger.warning("ç³»ç»Ÿå·²ç»åœ¨è¿è¡Œ")
            return
            
        self.is_running = True
        self.system_state = SystemState.IDLE
        logger.info("ç³»ç»Ÿå·²å¯åŠ¨")
        
    def stop(self):
        """åœæ­¢ç³»ç»Ÿ"""
        if not self.is_running:
            logger.warning("ç³»ç»Ÿå·²ç»åœæ­¢")
            return
            
        self.is_running = False
        self.system_state = SystemState.IDLE
        logger.info("ç³»ç»Ÿå·²åœæ­¢")
        
    def process_input(self, text: str = None, audio: bytes = None, image: bytes = None) -> Optional[str]:
        """å¤„ç†å¤šæ¨¡æ€è¾“å…¥ï¼Œé›†æˆè¡¨æƒ…ã€æ‰‹åŠ¿ã€å£°çº¹ã€ç”»åƒã€åŠ å¯†ç­‰"""
        if not self.is_running:
            logger.error("ç³»ç»Ÿæœªå¯åŠ¨")
            return None
        try:
            multimodal_features = {}
            # æ–‡æœ¬è¾“å…¥
            if text:
                self.system_state = SystemState.THINKING
                # å¯¹äºæ–‡æœ¬è¾“å…¥ï¼Œä½¿ç”¨æœ€åè¯†åˆ«çš„ç”¨æˆ·æˆ–è®¿å®¢
                current_user_id = self.user_manager.last_recognized_user.user_id if self.user_manager.last_recognized_user else 'visitor'
                user_profile = None
                if current_user_id != 'visitor' and self.user_manager:
                    user_profile = self.user_manager.get_user_profile(current_user_id)
                    
                response = self.dialogue_manager.generate_response(
                    prompt=text,
                    user_id=current_user_id,
                    user_profile=user_profile
                )
                self.system_state = SystemState.SPEAKING
                self.last_response_time = datetime.now()
                return response
            # éŸ³é¢‘è¾“å…¥
            if audio:
                self.system_state = SystemState.THINKING
                audio_text = self.voice_recognizer.recognize(audio)
                voice_feature = self.voice_recognizer.extract_voice_feature(np.frombuffer(audio, dtype=np.int16).astype(np.float32))
                multimodal_features['voice'] = voice_feature
                user_id, voice_conf = self.voice_recognizer.match_voice(voice_feature)
                multimodal_features['voice_user'] = user_id
                
                # æ‰“å°å£°çº¹è¯†åˆ«ç»“æœ
                if user_id and user_id != 'unknown':
                    logger.info(f"ğŸ¤ å£°çº¹è¯†åˆ«: {user_id} (ç½®ä¿¡åº¦={voice_conf:.2f})")
                else:
                    logger.info("ğŸ¤ å£°çº¹è¯†åˆ«: æœªè¯†åˆ«åˆ°å·²çŸ¥ç”¨æˆ·")
                
                if audio_text:
                    logger.info(f"ğŸ“ è¯­éŸ³è½¬æ–‡å­—: {audio_text}")
                    
                    # è·å–ç”¨æˆ·ç”»åƒä¿¡æ¯
                    user_profile = None
                    if user_id and user_id != 'unknown' and self.user_manager:
                        user_profile = self.user_manager.get_user_profile(user_id)
                        if user_profile:
                            logger.info(f"ğŸ‘¤ ç”¨æˆ·ç”»åƒ: {user_profile['name']} (è®¿é—®{user_profile['visit_count']}æ¬¡, æ ‡ç­¾: {', '.join(user_profile['tags'])})")
                    
                    # ç”Ÿæˆä¸ªæ€§åŒ–å›å¤
                    response = self.dialogue_manager.generate_response(
                        audio_text=audio_text,
                        user_id=user_id,
                        user_profile=user_profile
                    )
                    self.system_state = SystemState.SPEAKING
                    self.last_response_time = datetime.now()
                    return response
                else:
                    logger.debug("æœªè¯†åˆ«åˆ°è¯­éŸ³å†…å®¹")
            # å›¾åƒè¾“å…¥
            if image:
                self.system_state = SystemState.THINKING
                try:
                    nparr = np.frombuffer(image, np.uint8)
                    frame = cv2.imdecode(nparr, cv2.IMREAD_COLOR)
                    if frame is not None:
                        # äººè„¸æ£€æµ‹
                        face_info = self.face_recognizer.detect(frame)
                        multimodal_features['face'] = face_info
                        if face_info.get('detected'):
                            logger.info(f"ğŸ‘¤ æ£€æµ‹åˆ°äººè„¸: ç½®ä¿¡åº¦={face_info.get('confidence', 0):.2f}")
                        
                        # è¡¨æƒ…è¯†åˆ«
                        emotion_info = self.emotion_recognizer.detect_emotion(frame)
                        multimodal_features['emotion'] = emotion_info
                        if emotion_info.get('detected'):
                            emotion = emotion_info.get('emotion', 'unknown')
                            confidence = emotion_info.get('confidence', 0)
                            logger.info(f"ğŸ˜Š æ£€æµ‹åˆ°è¡¨æƒ…: {emotion} (ç½®ä¿¡åº¦={confidence:.2f})")
                        
                        # æ‰‹åŠ¿è¯†åˆ«
                        gesture_info = self.gesture_recognizer.detect_gesture(frame)
                        multimodal_features['gesture'] = gesture_info
                        if gesture_info.get('detected'):
                            gesture = gesture_info.get('gesture', 'unknown')
                            confidence = gesture_info.get('confidence', 0)
                            logger.info(f"ğŸ‘‹ æ£€æµ‹åˆ°æ‰‹åŠ¿: {gesture} (ç½®ä¿¡åº¦={confidence:.2f})")
                        # å¤šæ¨¡æ€èº«ä»½èåˆï¼ˆå¦‚æœ‰ identity_managerï¼‰
                        if self.identity_manager:
                            user_id, confidences = self.identity_manager.fuse_identities(
                                face_embedding=face_info.get('face_embedding'),
                                voice_embedding=multimodal_features.get('voice'),
                                emotion=emotion_info,
                                gesture=gesture_info
                            )
                            multimodal_features['user_id'] = user_id
                        # ç”»åƒåŠ¨æ€è¡¥å…¨
                        if self.user_manager:
                            profile_data = {
                                'face_info': face_info,
                                'voice_feature': multimodal_features.get('voice'),
                                'emotion_info': emotion_info,
                                'gesture_info': gesture_info
                            }
                            user_id = multimodal_features.get('user_id', 'visitor')
                            self.user_manager.update_user_profile(user_id, profile_data)
                        # åªè®°å½•è§†è§‰ä¿¡æ¯ï¼Œä¸è°ƒç”¨å¤§æ¨¡å‹
                        logger.debug("å·²è®°å½•è§†è§‰ä¿¡æ¯ï¼Œç­‰å¾…ç”¨æˆ·è¯­éŸ³è¾“å…¥")
                except Exception as e:
                    logger.error(f"å›¾åƒå¤„ç†å¤±è´¥: {e}")
            self.system_state = SystemState.IDLE
            return None
        except Exception as e:
            logger.error(f"å¤„ç†è¾“å…¥å¤±è´¥: {e}")
            self.system_state = SystemState.ERROR
            return None
            
    def get_system_state(self) -> SystemState:
        """è·å–ç³»ç»ŸçŠ¶æ€"""
        return self.system_state
        
    def get_last_response_time(self) -> datetime:
        """è·å–æœ€åä¸€æ¬¡å“åº”æ—¶é—´"""
        return self.last_response_time 

    def process_input_stream(self, text: str = None, audio: bytes = None, image: bytes = None):
        """å¤„ç†å¤šæ¨¡æ€è¾“å…¥ï¼Œæµå¼è¾“å‡º"""
        if not self.is_running:
            logger.error("ç³»ç»Ÿæœªå¯åŠ¨")
            yield None
            return
        try:
            if text:
                self.system_state = SystemState.THINKING
                # å¯¹äºæ–‡æœ¬è¾“å…¥ï¼Œä½¿ç”¨æœ€åè¯†åˆ«çš„ç”¨æˆ·æˆ–è®¿å®¢
                current_user_id = self.user_manager.last_recognized_user.user_id if self.user_manager.last_recognized_user else 'visitor'
                user_profile = None
                if current_user_id != 'visitor' and self.user_manager:
                    user_profile = self.user_manager.get_user_profile(current_user_id)
                    
                for chunk in self.dialogue_manager.generate_response_stream(
                    prompt=text,
                    user_id=current_user_id,
                    user_profile=user_profile
                ):
                    yield chunk
                self.system_state = SystemState.SPEAKING
                self.last_response_time = datetime.now()
                return
            if audio:
                self.system_state = SystemState.THINKING
                audio_text = self.voice_recognizer.recognize(audio)
                if audio_text:
                    logger.info(f"è¯†åˆ«åˆ°è¯­éŸ³: {audio_text}")
                    
                    # è·å–å£°çº¹ç‰¹å¾å’Œç”¨æˆ·ä¿¡æ¯
                    voice_feature = self.voice_recognizer.extract_voice_feature(np.frombuffer(audio, dtype=np.int16).astype(np.float32))
                    user_id, voice_conf = self.voice_recognizer.match_voice(voice_feature) if voice_feature is not None else (None, 0.0)
                    
                    # è·å–ç”¨æˆ·ç”»åƒä¿¡æ¯
                    user_profile = None
                    if user_id and user_id != 'unknown' and self.user_manager:
                        user_profile = self.user_manager.get_user_profile(user_id)
                        if user_profile:
                            logger.info(f"ğŸ‘¤ ç”¨æˆ·ç”»åƒ: {user_profile['name']} (è®¿é—®{user_profile['visit_count']}æ¬¡)")
                    
                    # æµå¼ç”Ÿæˆä¸ªæ€§åŒ–å›å¤
                    for chunk in self.dialogue_manager.generate_response_stream(
                        audio_text=audio_text,
                        user_id=user_id,
                        user_profile=user_profile
                    ):
                        yield chunk
                    self.system_state = SystemState.SPEAKING
                    self.last_response_time = datetime.now()
                    return
                else:
                    logger.debug("æœªè¯†åˆ«åˆ°è¯­éŸ³å†…å®¹")
            if image:
                self.system_state = SystemState.THINKING
                try:
                    nparr = np.frombuffer(image, np.uint8)
                    frame = cv2.imdecode(nparr, cv2.IMREAD_COLOR)
                    if frame is not None:
                        face_info = self.face_recognizer.detect(frame)
                        if face_info and face_info.get("detected"):
                            logger.info("ğŸ‘¤ æ£€æµ‹åˆ°äººè„¸")
                            logger.debug("å·²è®°å½•è§†è§‰ä¿¡æ¯ï¼Œç­‰å¾…ç”¨æˆ·è¯­éŸ³è¾“å…¥")
                            # ä¸è°ƒç”¨å¤§æ¨¡å‹ï¼Œåªè®°å½•è§†è§‰ä¿¡æ¯
                except Exception as e:
                    logger.error(f"å›¾åƒå¤„ç†å¤±è´¥: {e}")
            self.system_state = SystemState.IDLE
            yield None
        except Exception as e:
            logger.error(f"æµå¼å¤„ç†è¾“å…¥å¤±è´¥: {e}")
            self.system_state = SystemState.ERROR
            yield None 

    # ç”»åƒåŠ å¯†å­˜å‚¨ã€åˆ é™¤æ¥å£
    def save_user_profiles(self, encrypt=True):
        if self.user_manager:
            data = self.user_manager.export_profiles()
            if encrypt:
                data = encrypt_data(data)
            with open('user_profiles.enc', 'wb') as f:
                f.write(data)
            logger.info("ç”¨æˆ·ç”»åƒå·²åŠ å¯†ä¿å­˜")
    def load_user_profiles(self, decrypt=True):
        if self.user_manager:
            with open('user_profiles.enc', 'rb') as f:
                data = f.read()
            if decrypt:
                data = decrypt_data(data)
            self.user_manager.import_profiles(data)
            logger.info("ç”¨æˆ·ç”»åƒå·²è§£å¯†åŠ è½½")
    def delete_user_profile(self, user_id):
        if self.user_manager:
            self.user_manager.delete_user_profile(user_id)
            logger.info(f"å·²åˆ é™¤ç”¨æˆ·ç”»åƒ: {user_id}")
    # é…ç½®çƒ­åŠ è½½ã€æ¨¡å—çƒ­æ’æ‹”æ¥å£ï¼ˆé¢„ç•™ï¼‰
    def reload_config(self):
        logger.info("é…ç½®çƒ­åŠ è½½åŠŸèƒ½é¢„ç•™")
    def reload_module(self, module_name):
        logger.info(f"æ¨¡å—çƒ­æ’æ‹”åŠŸèƒ½é¢„ç•™: {module_name}") 